---
layout: post
title: Week 10
---
## July 15 - July 19

I am excited to report that I finally got to work with some real data generated by children in the learning environment this week! The week leading up to this data collection was a little stressful but definitely worth it!

Last week, Jeff and the WHIMC development team pushed some new updates and reset the learning environment to prepare for the upcoming BarrelBot camp. While they were doing this, I was working on my Python script for ONA when suddenly my script began outputting CSV files that didn't make sense. I didn't understand what was happening, but I eventually resolved this issue over the weekend by deleting one line of code. That one line of code was a patch I had added several weeks ago to adjust the coordinates of puzzle regions from the database to correspond with the actual virtual environment, but the coordinates must have changed when they reset the environment. So, I removed this patch to let the information in the database determine the z-coordinates of puzzle regions and presto chango! My script worked again!

After debugging my script, I finished writing the code to add a status column to my ONA event log. I was over the moon that I had finished everything on Saturday because Luc and Juan had left town for a conference where they would be hosting a workshop, and Luc had shared a Zoom link with me that would allow me to attend this workshop on Sunday.

However, my plans shifted when I received a late-night Slack message from Jeff asking if I'd be willing to test the environment one last time for him. This was completely optional, but I wanted to help. So, first thing Sunday morning, I asked my roommate Katelyn if she'd be interested in generating some data for me, and she was more than happy to help. I set everything up for her on my laptop and gave her a quick tutorial on how to play. Then, I hung out nearby and took a few notes. She solved the first two puzzles, but she couldn't complete the third due to a bug in the learning environment, which I let Jeff know about immediately.

After Katelyn decided to stop playing the game, I ran the data she generated through my Python script for ONA only to find that the output it generated was a confusing mess. At this point, my script was working exactly as intended, but the data from the database for button presses and successful outcomes was not logging correctly. I told Luc about the situation over Slack and began patching my script to work around these issues so I'd be ready for the data collection starting the next day. 

I was still able to attend portions of the workshop Luc and Juan were hosting, but I lost track of time while I was coding and I missed the panel I was hoping to attend in the afternoon. Fortunately, despite juggling these activities, I managed to patch the latest version of my script so I'd be ready first thing Monday morning!

On Monday, data collection began. On the first day, roughly 100 campers were divided into 5 groups. These groups spent the day trying out the different camp experiences being offered, one of which was WHIMC's BarrelBot learning environment. Then, students signed up for the activity they wanted to spend the rest of the week doing. Unsurprisingly, BarrelBot was the most popular choice! Seventeen students returned on Tuesday to work through the BarrelBot learning environment, starting from Puzzle 1 for a second time. This was advantageous because I wouldn't be able to analyze user behavior beyond this point but with so many actual students running through the first 3 puzzles, I was hopeful about what I might discover.

Accordingly, I spent the majority of my week working on my technical report and exploring Monday and Tuesday's data, but I didn't get as far as I would have liked because I was struggling to identify the 5 separate groups who all used the same user accounts on Monday. While attempting to resolve this issue on my own, I reached out to Jeff a couple of times for help. Eventually, I realized that there had been problems on-site getting the first group going, one account being used by adults had been set up last minute for students but they had to be teleported around the environment, and all the data from the fourth group was missing from the database. The remaining data, from groups 2, 3, and 5, appeared reliable, so I proceeded under the assumption that I was looking at the behavior of 45 junior high school-aged students. 

Unfortunately, I found out late Friday afternoon that there had not been enough computers for all the students in each of the 5 groups throughout the day. Some of the user data was generated by individual students and other user data was generated by two students sitting next to one another on the same computer working cooperatively, and I do not know how to distinguish between these users in the dataset.

Unaware of this limitation, I was struggling to make generalizations about student behavior using ONA, but I was hopeful that looking at Tuesday's data might help me make sense of the mathematical visualizations I was seeing on webENA. From Wednesday onward, I focused my attention on Tuesday's data from a group of 17 students. While exploring this dataset, I saw some interesting behavior, but I was concerned that real-life interventions were occurring that might disrupt my ability to make generalizations about student behavior to identify markers of struggle and persistence. 

To my dismay, my concerns were not unfounded. I saw one group of students (who may have been persisting) suddenly give up while working on Puzzle 3, and I wasn't certain if they gave up because they were struggling or if they had been instructed to move on to Puzzle 4 because it is a cooperative area where pairs of students build BarrelBot puzzles for one another to solve. I also saw another group of students who appeared to be struggling with Puzzle 2 move on to Puzzle 3. Suddenly, several students who had been unable to complete the second puzzle were able to complete a more complex puzzle. I suspected that this group was struggling the most, so they were assisted in solving Puzzle 3 before moving on to the cooperative area with everyone else. My suspicions about both groups were confirmed on Friday afternoon by Jeff, who had been there in person.

Despite these setbacks, there were 2 student users in this data set that I think may have shown signs of struggle and persistence on Puzzle 2 and Puzzle 3. It's not a lot of data to go on, but it's a start. I wish I had more time and more data, but I suppose that is what the limitations and future works sections of technical reports are for.
